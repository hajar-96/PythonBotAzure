{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOpZ7BBk5GIC2XceEa3Yv3/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hajar-96/PythonBotAzure/blob/main/Untitled5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJKZxvA6xDd0"
      },
      "outputs": [],
      "source": [
        "\n",
        "#bagging\n",
        "from tree import build_tree, print_tree, car_data, car_labels\n",
        "import random\n",
        "random.seed(4)\n",
        "tree=build_tree(car_data, car_labels)\n",
        "print_tree(tree)\n",
        "indices=[]\n",
        "for i in range(1000):\n",
        "  #generate a random number between 1 and 1000\n",
        "  indices.append(random.randint(0,999))\n",
        "  data_subset=[car_data[index] for index in indices]\n",
        "  labels_subset=[car_labels[index] for index in indices]\n",
        "  subset_tree = build_tree(data_subset, labels_subset)\n",
        "  print_tree(subset_tree)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Bagging Features\n",
        "#random.choice() returns a list of values between 0 and the first parameter. \n",
        "#The size of the list is determined by the second parameter. And we can choose without replacement by setting replace = False\n",
        "from tree import car_data, car_labels, split, information_gain\n",
        "import random\n",
        "import numpy as np\n",
        "np.random.seed(1)\n",
        "random.seed(4)\n",
        "\n",
        "def find_best_split(dataset, labels):\n",
        "    best_gain = 0\n",
        "    best_feature = 0\n",
        "    #Create features here\n",
        "    features=np.random.choice(len(dataset[0]), 3, replace = False)\n",
        "    for feature in features:\n",
        "        data_subsets, label_subsets = split(dataset, labels, feature)\n",
        "        gain = information_gain(labels, label_subsets)\n",
        "        if gain > best_gain:\n",
        "            best_gain, best_feature = gain, feature\n",
        "    return best_gain, best_feature\n",
        "  \n",
        "indices = [random.randint(0, 999) for i in range(1000)]\n",
        "\n",
        "data_subset = [car_data[index] for index in indices]\n",
        "labels_subset = [car_labels[index] for index in indices]\n",
        "print(find_best_split(data_subset,labels_subset))"
      ],
      "metadata": {
        "id": "9eAr_bC2uHUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#classify by creating 20 trees in our random forest\n",
        "from tree import build_tree, print_tree, car_data, car_labels, classify\n",
        "import random\n",
        "random.seed(4)\n",
        "\n",
        "# The features are the price of the car, the cost of maintenance, the number of doors, the number of people the car can hold, the size of the trunk, and the safety rating\n",
        "unlabeled_point = ['high', 'vhigh', '3', 'more', 'med', 'med']\n",
        "#we have 20 trees in our random forest algorithm\n",
        "predictions=[]\n",
        "for i in range(20):\n",
        "  \n",
        "  indices = [random.randint(0, 999) for i in range(1000)]\n",
        "  data_subset = [car_data[index] for index in indices]\n",
        "  labels_subset = [car_labels[index] for index in indices]\n",
        "  subset_tree = build_tree(data_subset, labels_subset)\n",
        "  predictions.append(classify(unlabeled_point, subset_tree))\n",
        "final_prediction=max(predictions, key=predictions.count) \n",
        "print(final_prediction)"
      ],
      "metadata": {
        "id": "Ex3IL7j87Mq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test Set\n",
        "from tree import training_data, training_labels, testing_data, testing_labels, make_random_forest, make_single_tree, classify\n",
        "import numpy as np\n",
        "import random\n",
        "np.random.seed(1)\n",
        "random.seed(1)\n",
        "\n",
        "tree = make_single_tree(training_data, training_labels)\n",
        "forest = make_random_forest(40, training_data, training_labels)\n",
        "single_tree_correct = 0\n",
        "forest_correct =0\n",
        "\n",
        "\n",
        "for i in range(len(testing_data)):\n",
        "  prediction = classify(testing_data[i], tree)\n",
        "  if prediction == testing_labels[i]:\n",
        "    single_tree_correct += 1\n",
        "  predictions = []\n",
        "  for forest_tree in forest:\n",
        "    predictions.append(classify(testing_data[i], forest_tree))\n",
        "  forest_prediction = max(predictions,key=predictions.count)\n",
        "  if forest_prediction == testing_labels[i]:\n",
        "    forest_correct += 1\n",
        "print(single_tree_correct/len(testing_data))\n",
        "print(forest_correct/len(testing_data))"
      ],
      "metadata": {
        "id": "ENGYpclO5Rnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Random Forest in Scikit-learn\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "import warnings\n",
        "warnings.warn = warn\n",
        "from cars import training_points, training_labels, testing_points, testing_labels\n",
        "import warnings\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier =RandomForestClassifier(n_estimators=2000,random_state=0)\n",
        "classifier.fit(training_points, training_labels)\n",
        "prediction=classifier.predict(testing_points)\n",
        "print(classifier.score(testing_points, testing_labels))\n"
      ],
      "metadata": {
        "id": "XL4AkZWjMhVn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}